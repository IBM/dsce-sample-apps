{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d80c305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### this is to make item categories\n",
    "\n",
    "import random\n",
    "\n",
    "# A much larger and more detailed data structure for products\n",
    "product_data = {\n",
    "    \"Electronics\": {\n",
    "        \"brands\": [\"Quantum\", \"Nova\", \"StarkTech\", \"Electron\", \"Pixelon\", \"SoundWave\"],\n",
    "        \"types\": [\"Smartphone\", \"Laptop\", \"Headphones\", \"Smart Display\", \"Tablet\", \"Drone\", \"Gaming Mouse\"],\n",
    "        \"features\": [\"5G\", \"4K HDR\", \"AI-Powered\", \"Noise-Cancelling\", \"Biometric\", \"Water-Resistant\", \"8K\"],\n",
    "        \"models\": [\"X1\", \"Pro Max\", \"Z-Series\", \"Vision\", \"Elite\", \"Core i9\", \"Aura\"],\n",
    "        \"patterns\": [\n",
    "            \"{brand} {model} {feature} {type}\",\n",
    "            \"{brand} {type} with {feature} Display\",\n",
    "            \"The all-new {brand} {model} {type}\",\n",
    "            \"{brand} {feature} {type} ({model})\",\n",
    "        ],\n",
    "        \"price_range\": (150.00, 500.00)\n",
    "    },\n",
    "    \"Apparel\": {\n",
    "        \"brands\": [\"Evergreen\", \"Apex Threads\", \"UrbanFlex\", \"Coastline\", \"Nomad Wear\", \"Terra Firma\"],\n",
    "        \"types\": [\"T-Shirt\", \"Hoodie\", \"Jeans\", \"Jacket\", \"Polo Shirt\", \"Blazer\", \"Shorts\"],\n",
    "        \"materials\": [\"Organic Cotton\", \"Merino Wool\", \"Recycled Polyester\", \"Denim\", \"Linen\", \"Performance Fabric\"],\n",
    "        \"styles\": [\"Vintage Wash\", \"Slim Fit\", \"Relaxed Fit\", \"Athletic Cut\", \"Tailored Fit\", \"V-Neck\"],\n",
    "        \"patterns\": [\n",
    "            \"{brand} {style} {material} {type}\",\n",
    "            \"{material} {type} by {brand}\",\n",
    "            \"The {brand} {style} {type}\",\n",
    "            \"{brand} Men's {style} {type}\",\n",
    "        ],\n",
    "        \"price_range\": (25.00, 250.00)\n",
    "    },\n",
    "    \"Home Goods\": {\n",
    "        \"brands\": [\"Aura Home\", \"Hearth & Hammer\", \"SimpleForm\", \"Rustic Living\", \"Veridian\", \"Stone & Hearth\"],\n",
    "        \"types\": [\"Coffee Mug\", \"Desk Lamp\", \"Bookshelf\", \"Scented Candle\", \"Dinnerware Set\", \"Plush Throw Blanket\"],\n",
    "        \"materials\": [\"Ceramic\", \"Solid Oak\", \"Brushed Steel\", \"Soy Wax\", \"Porcelain\", \"Bamboo\", \"Velvet\"],\n",
    "        \"descriptors\": [\"Artisan\", \"Minimalist\", \"Industrial\", \"Hand-Poured\", \"Hand-Woven\", \"Eco-Conscious\"],\n",
    "        \"patterns\": [\n",
    "            \"{descriptor} {material} {type} by {brand}\",\n",
    "            \"{brand} {material} {type}\",\n",
    "            \"The {descriptor} {type} from {brand}\"\n",
    "        ],\n",
    "        \"price_range\": (15.00, 400.00)\n",
    "    },\n",
    "    \"Food & Drink\": {\n",
    "        \"brands\": [\"Harvest Moon Organics\", \"The Gilded Bean\", \"Alpine Spring\", \"NectarFlow\", \"Crumb & Co.\"],\n",
    "        \"types\": [\"Artisanal Coffee\", \"Gourmet Pasta\", \"Organic Kombucha\", \"Dark Chocolate Bar\", \"Sourdough Bread\"],\n",
    "        \"attributes\": [\"Fair Trade\", \"Gluten-Free\", \"Small Batch\", \"Cold Brew\", \"Single-Origin\", \"Keto-Friendly\"],\n",
    "        \"flavor_profiles\": [\"Rich & Nutty\", \"Bright & Citrusy\", \"Bold & Spicy\", \"Sweet & Savory\"],\n",
    "        \"patterns\": [\n",
    "            \"{brand} {attribute} {type}\",\n",
    "            \"{type} - {flavor_profiles}, {brand}\",\n",
    "            \"Small Batch {type} ({attributes})\",\n",
    "            \"{brand} {flavor_profiles} {type}\",\n",
    "        ],\n",
    "        \"price_range\": (5.00, 75.00)\n",
    "    },\n",
    "    \"Sports & Outdoors\": {\n",
    "        \"brands\": [\"Trailblazer\", \"Summit Gear\", \"AquaStride\", \"Peak Performance\", \"IronGrip Fitness\"],\n",
    "        \"types\": [\"Hiking Backpack\", \"Yoga Mat\", \"Insulated Water Bottle\", \"Trail Running Shoes\", \"Camping Tent\"],\n",
    "        \"features\": [\"All-Weather\", \"UV Protection\", \"Lightweight Frame\", \"Moisture-Wicking\", \"Quick-Dry\"],\n",
    "        \"specs\": [\"50L\", \"24oz\", \"Pro-Grip\", \"4-Person\", \"XL\"],\n",
    "        \"patterns\": [\n",
    "            \"{brand} {specs} {feature} {type}\",\n",
    "            \"The {brand} {type} for {features} Adventures\",\n",
    "            \"{brand} {type} ({specs})\",\n",
    "        ],\n",
    "        \"price_range\": (20.00, 400.00) \n",
    "    },\n",
    "    \"Beauty & Personal Care\": {\n",
    "        \"brands\": [\"Etherea\", \"BioDerm\", \"Pure Elements\", \"Verde\", \"Celestial Skincare\"],\n",
    "        \"types\": [\"Hydrating Face Serum\", \"Exfoliating Scrub\", \"Vitamin C Cream\", \"Clay Mask\", \"Night Repair Oil\"],\n",
    "        \"ingredients\": [\"Hyaluronic Acid\", \"Retinol\", \"Charcoal\", \"Tea Tree Oil\", \"Niacinamide\", \"Peptides\"],\n",
    "        \"benefits\": [\"Anti-Aging\", \"Brightening\", \"Deep Cleansing\", \"Firming\", \"Soothing\"],\n",
    "        \"patterns\": [\n",
    "            \"{brand} {benefits} {type} with {ingredient}\",\n",
    "            \"{brand} {ingredient} {type}\",\n",
    "            \"{benefits} {type} by {brand}\",\n",
    "        ],\n",
    "        \"price_range\": (12.00, 125.00)\n",
    "    }\n",
    "}\n",
    "\n",
    "categories = list(product_data.keys())\n",
    "\n",
    "def generate_realistic_product_name():\n",
    "    \"\"\"\n",
    "    Generates a single realistic product name by picking a random category\n",
    "    and using its specific patterns and components.\n",
    "    \"\"\"\n",
    "    # 1. Pick a random category\n",
    "    category_name = random.choice(list(product_data.keys()))\n",
    "    category = product_data[category_name]\n",
    "\n",
    "    # 2. Pick a random name pattern from that category\n",
    "    pattern = random.choice(category['patterns'])\n",
    "\n",
    "    # 3. Create a dictionary of the components to fill the pattern\n",
    "    #    e.g., {'brand': 'Quantum', 'model': 'X1', ...}\n",
    "    components = {}\n",
    "    for key, values in category.items():\n",
    "        if key != 'patterns':\n",
    "            # Handle potential pluralization issues in patterns by providing both\n",
    "            # For example, a pattern can use {feature} or {features}\n",
    "            singular_key = key.rstrip('s')\n",
    "            plural_key = singular_key + 's'\n",
    "            chosen_value = random.choice(values)\n",
    "            components[singular_key] = chosen_value\n",
    "            components[plural_key] = chosen_value\n",
    "\n",
    "    # 4. Fill the pattern with the randomly selected components\n",
    "    return category_name,pattern.format(**components)\n",
    "\n",
    "\n",
    "def generate_price_for_category(category_name):\n",
    "    \"\"\"\n",
    "    Generates a realistic price based on the product's category.\n",
    "    \"\"\"\n",
    "    min_price, max_price = product_data[category_name]['price_range']\n",
    "\n",
    "    base_price = random.uniform(min_price, max_price)\n",
    "    return int(round(base_price,0))\n",
    "cat,name=generate_realistic_product_name()\n",
    "generate_price_for_category(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70eeca6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ reorders.csv generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "Faker.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Sample supplier and SKU IDs for consistency\n",
    "sku_ids = [f\"SKU{i+1:04}\" for i in range(100)]\n",
    "supplier_ids = [f\"S{i+1:03}\" for i in range(20)]\n",
    "\n",
    "# Generate reorders\n",
    "num_reorders = 300\n",
    "reorders = pd.DataFrame({\n",
    "    \"reorder_id\": [f\"REORDER{i+1:05}\" for i in range(num_reorders)],\n",
    "    \"sku_id\": [random.choice(sku_ids) for _ in range(num_reorders)],\n",
    "    \"reorder_qty\": [random.randint(20, 200) for _ in range(num_reorders)],\n",
    "    \"reorder_date\": [fake.date_between(start_date='-6m', end_date='-1m') for _ in range(num_reorders)],\n",
    "    \"status\": [random.choice(['pending', 'fulfilled', 'cancelled']) for _ in range(num_reorders)],\n",
    "    \"supplier_id\": [random.choice(supplier_ids) for _ in range(num_reorders)],\n",
    "    \"price_per_unit\": [round(random.uniform(10, 100), 2) for _ in range(num_reorders)],\n",
    "    \n",
    "})\n",
    "\n",
    "# Fulfilment date: only if status is fulfilled or pending\n",
    "reorders[\"reorder_fulfilment_date\"] = reorders.apply(\n",
    "    lambda row: fake.date_between(start_date=row[\"reorder_date\"], end_date='today')\n",
    "    if row[\"status\"] in ['fulfilled', 'pending'] else \"\", axis=1\n",
    ")\n",
    "\n",
    "# Save to CSV\n",
    "reorders.to_csv(\"reorders.csv\", index=False)\n",
    "print(\"✅ reorders.csv generated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "658407fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Supplier Data\n",
    "num_suppliers = 20\n",
    "suppliers = pd.DataFrame({\n",
    "    \"supplier_id\": [f\"S{i+1:03}\" for i in range(num_suppliers)],\n",
    "    \"supplier_name\": [fake.company() for _ in range(num_suppliers)],\n",
    "    \"contact_email\": [fake.company_email() for _ in range(num_suppliers)],\n",
    "    \"phone_number\": [fake.phone_number() for _ in range(num_suppliers)],\n",
    "    \"region\": [fake.state() for _ in range(num_suppliers)]\n",
    "})\n",
    "\n",
    "suppliers.to_csv(\"supplier.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3093cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sku_ids = [f\"SKU{i+1:04}\" for i in range(100)]\n",
    "supplier_sku = pd.DataFrame([\n",
    "    {\n",
    "        \"sku_id\": random.choice(sku_ids),\n",
    "        \"supplier_id\": random.choice(suppliers[\"supplier_id\"]),\n",
    "        \"min_purchase_qty\": random.randint(10, 50),\n",
    "        \"max_purchase_qty\": random.randint(100, 500),\n",
    "        \"min_price\": round(random.uniform(10, 50), 2),\n",
    "        \"max_price\": round(random.uniform(51, 150), 2),\n",
    "        \"lead_time_days\": random.randint(2, 10)\n",
    "    }\n",
    "    for _ in range(300)\n",
    "])\n",
    "\n",
    "supplier_sku.to_csv(\"supplier-sku.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5753cb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_ids = [f\"C{i+1:04}\" for i in range(200)]\n",
    "\n",
    "number_of_records=3000\n",
    "sales_data = pd.DataFrame({\n",
    "    \"sale_id\": [f\"SALE{i+1:05}\" for i in range(number_of_records)],\n",
    "    \"customer_id\": [random.choice(customer_ids) for _ in range(number_of_records)],\n",
    "    \"sku_id\": [random.choice(sku_ids) for _ in range(number_of_records)],\n",
    "    \"quantity\": [random.randint(1, 10) for _ in range(number_of_records)],\n",
    "    \"sale_date\": [fake.date_between(start_date='-1y', end_date='today') for _ in range(number_of_records)],\n",
    "    \"status\": [random.choice([\"completed\", \"pending\", \"cancelled\"]) for _ in range(number_of_records)],\n",
    "    \"fulfilled\": [random.choice([True, False]) for _ in range(number_of_records)],\n",
    "    \"amount\": [round(random.uniform(20, 500), 2) for _ in range(number_of_records)],\n",
    "    \"coupon\": [random.choice([\"DISC10\", \"SAVE20\", \"\", \"NEW5\"]) for _ in range(number_of_records)],\n",
    "    \"store_id\": [\"STORE01\" for _ in range(number_of_records)]\n",
    "})\n",
    "\n",
    "sales_data.to_csv(\"sales_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3f1829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from app.config.cluster_info import customer_cluster_explanations,sku_cluster_explanations\n",
    "\n",
    "#json.loads('config/cluster_info.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faf0749b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "segments = ['Silver', 'Gold', 'Platinum']\n",
    "#categories = ['Electronics', 'Grocery', 'Clothing', 'Books', 'Home']\n",
    "\n",
    "\n",
    "customer_clusters = list(customer_cluster_explanations.values())\n",
    "\n",
    "customer = pd.DataFrame({\n",
    "    \"customer_id\": customer_ids,\n",
    "    \"name\": [fake.name() for _ in customer_ids],\n",
    "    \"region\": [fake.state() for _ in customer_ids],\n",
    "    \"segment\": [random.choice(segments) for _ in customer_ids],\n",
    "    \"cluster_id\":[random.randint(0, 5) for _ in customer_ids],\n",
    "    \"cluster_info\":[random.choice(customer_clusters) for _ in customer_ids],\n",
    "    \"gender\": [random.choice(['Male', 'Female', 'Other']) for _ in customer_ids],\n",
    "    \"birthdate\": [fake.date_of_birth(minimum_age=18, maximum_age=65) for _ in customer_ids],\n",
    "    \"contact info\": [fake.phone_number() for _ in customer_ids],\n",
    "    \"buying power\": [random.randint(1, 5) for _ in customer_ids],\n",
    "    \"fav category\": [random.choice(categories) for _ in customer_ids],\n",
    "    \"customer segment\": [random.choice(segments) for _ in customer_ids],\n",
    "    \"last purchase date\": [fake.date_between(start_date='-6m', end_date='today') for _ in customer_ids],\n",
    "    \"income level\": [random.choice(['Low', 'Medium', 'High']) for _ in customer_ids],\n",
    "    \"location\": [fake.city() for _ in customer_ids],\n",
    "    \"no_of_dependents\": [random.randint(0, 5) for _ in customer_ids],\n",
    "    \"purchase_frequency\": [random.randint(1, 30) for _ in customer_ids],\n",
    "    \"click on marketing emails\": [random.choice([True, False]) for _ in customer_ids],\n",
    "    \"return rate\": [round(random.uniform(0, 0.3), 2) for _ in customer_ids],\n",
    "    \"usage frequency of (app or site)\": [random.choice(['Low', 'Medium', 'High']) for _ in customer_ids],\n",
    "    \"total spend\": [round(random.uniform(100, 5000), 2) for _ in customer_ids],\n",
    "    \"loyalty\": [random.choice(['Bronze', 'Silver', 'Gold', 'Platinum']) for _ in customer_ids],\n",
    "})\n",
    "\n",
    "customer.to_csv(\"customer.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "924e4f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the ff to get the categories for inventory\n",
    "\n",
    "df = sales_data.copy()\n",
    "df['item_amount']= df['amount']/df['quantity']\n",
    "ranked_sales_data=df.groupby([\"sku_id\"])[['quantity','amount']].sum().sort_values('quantity',ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b8e1df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sale_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>sku_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>sale_date</th>\n",
       "      <th>status</th>\n",
       "      <th>fulfilled</th>\n",
       "      <th>amount</th>\n",
       "      <th>coupon</th>\n",
       "      <th>store_id</th>\n",
       "      <th>item_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SALE00001</td>\n",
       "      <td>C0158</td>\n",
       "      <td>SKU0045</td>\n",
       "      <td>10</td>\n",
       "      <td>2025-04-10</td>\n",
       "      <td>completed</td>\n",
       "      <td>True</td>\n",
       "      <td>302.87</td>\n",
       "      <td></td>\n",
       "      <td>STORE01</td>\n",
       "      <td>30.287000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SALE00002</td>\n",
       "      <td>C0159</td>\n",
       "      <td>SKU0088</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-06-05</td>\n",
       "      <td>cancelled</td>\n",
       "      <td>False</td>\n",
       "      <td>483.24</td>\n",
       "      <td>SAVE20</td>\n",
       "      <td>STORE01</td>\n",
       "      <td>161.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SALE00003</td>\n",
       "      <td>C0158</td>\n",
       "      <td>SKU0046</td>\n",
       "      <td>6</td>\n",
       "      <td>2024-10-12</td>\n",
       "      <td>completed</td>\n",
       "      <td>False</td>\n",
       "      <td>50.14</td>\n",
       "      <td></td>\n",
       "      <td>STORE01</td>\n",
       "      <td>8.356667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SALE00004</td>\n",
       "      <td>C0063</td>\n",
       "      <td>SKU0046</td>\n",
       "      <td>2</td>\n",
       "      <td>2024-12-27</td>\n",
       "      <td>pending</td>\n",
       "      <td>False</td>\n",
       "      <td>418.19</td>\n",
       "      <td></td>\n",
       "      <td>STORE01</td>\n",
       "      <td>209.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SALE00005</td>\n",
       "      <td>C0166</td>\n",
       "      <td>SKU0081</td>\n",
       "      <td>6</td>\n",
       "      <td>2025-06-10</td>\n",
       "      <td>pending</td>\n",
       "      <td>False</td>\n",
       "      <td>220.28</td>\n",
       "      <td>SAVE20</td>\n",
       "      <td>STORE01</td>\n",
       "      <td>36.713333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>SALE02996</td>\n",
       "      <td>C0126</td>\n",
       "      <td>SKU0039</td>\n",
       "      <td>8</td>\n",
       "      <td>2025-05-07</td>\n",
       "      <td>completed</td>\n",
       "      <td>True</td>\n",
       "      <td>54.56</td>\n",
       "      <td>NEW5</td>\n",
       "      <td>STORE01</td>\n",
       "      <td>6.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>SALE02997</td>\n",
       "      <td>C0101</td>\n",
       "      <td>SKU0063</td>\n",
       "      <td>9</td>\n",
       "      <td>2025-01-21</td>\n",
       "      <td>completed</td>\n",
       "      <td>False</td>\n",
       "      <td>163.95</td>\n",
       "      <td>DISC10</td>\n",
       "      <td>STORE01</td>\n",
       "      <td>18.216667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>SALE02998</td>\n",
       "      <td>C0191</td>\n",
       "      <td>SKU0056</td>\n",
       "      <td>8</td>\n",
       "      <td>2025-05-07</td>\n",
       "      <td>pending</td>\n",
       "      <td>False</td>\n",
       "      <td>314.45</td>\n",
       "      <td>DISC10</td>\n",
       "      <td>STORE01</td>\n",
       "      <td>39.306250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>SALE02999</td>\n",
       "      <td>C0041</td>\n",
       "      <td>SKU0095</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-07-12</td>\n",
       "      <td>pending</td>\n",
       "      <td>True</td>\n",
       "      <td>65.02</td>\n",
       "      <td>SAVE20</td>\n",
       "      <td>STORE01</td>\n",
       "      <td>32.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>SALE03000</td>\n",
       "      <td>C0005</td>\n",
       "      <td>SKU0040</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-03-18</td>\n",
       "      <td>pending</td>\n",
       "      <td>False</td>\n",
       "      <td>126.26</td>\n",
       "      <td></td>\n",
       "      <td>STORE01</td>\n",
       "      <td>63.130000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sale_id customer_id   sku_id  quantity   sale_date     status  \\\n",
       "0     SALE00001       C0158  SKU0045        10  2025-04-10  completed   \n",
       "1     SALE00002       C0159  SKU0088         3  2025-06-05  cancelled   \n",
       "2     SALE00003       C0158  SKU0046         6  2024-10-12  completed   \n",
       "3     SALE00004       C0063  SKU0046         2  2024-12-27    pending   \n",
       "4     SALE00005       C0166  SKU0081         6  2025-06-10    pending   \n",
       "...         ...         ...      ...       ...         ...        ...   \n",
       "2995  SALE02996       C0126  SKU0039         8  2025-05-07  completed   \n",
       "2996  SALE02997       C0101  SKU0063         9  2025-01-21  completed   \n",
       "2997  SALE02998       C0191  SKU0056         8  2025-05-07    pending   \n",
       "2998  SALE02999       C0041  SKU0095         2  2025-07-12    pending   \n",
       "2999  SALE03000       C0005  SKU0040         2  2025-03-18    pending   \n",
       "\n",
       "      fulfilled  amount  coupon store_id  item_amount  \n",
       "0          True  302.87          STORE01    30.287000  \n",
       "1         False  483.24  SAVE20  STORE01   161.080000  \n",
       "2         False   50.14          STORE01     8.356667  \n",
       "3         False  418.19          STORE01   209.095000  \n",
       "4         False  220.28  SAVE20  STORE01    36.713333  \n",
       "...         ...     ...     ...      ...          ...  \n",
       "2995       True   54.56    NEW5  STORE01     6.820000  \n",
       "2996      False  163.95  DISC10  STORE01    18.216667  \n",
       "2997      False  314.45  DISC10  STORE01    39.306250  \n",
       "2998       True   65.02  SAVE20  STORE01    32.510000  \n",
       "2999      False  126.26          STORE01    63.130000  \n",
       "\n",
       "[3000 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e92431b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#simplify forecasting based on trend\n",
    "\n",
    "df['sale_date']=df['sale_date'].astype('datetime64[ns]')\n",
    "#this will only work if you have 1 year worth of data\n",
    "#df['weekofyear']=df['sale_date'].apply(lambda x:'{}-{}'.format(x.year,x.isocalendar().week))\n",
    "df['weekofyear']=df['sale_date'].apply(lambda x:'{}-{}'.format(x.year,x.month))\n",
    "\n",
    "historical_sales=df.groupby(['sku_id','weekofyear'])['quantity'].sum()#.agg(np.median,np.percentile(q=25),np.percentile(q=75))\n",
    "weekly_historical_sales=historical_sales.groupby('sku_id').describe(percentiles=[.25,.5,.75])\n",
    "weekly_forecast_demand = weekly_historical_sales.apply(lambda x:random.randint(int(x['min']),int(x['max'])),axis=1)\n",
    "\n",
    "weekly_forecast_demand=weekly_forecast_demand.reset_index().rename(columns={0:'quantity'})\n",
    "\n",
    "weekly_forecast_demand.to_csv(\"demand_forecast.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afb48b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#genereate the products and the categories\n",
    "product_names_set = set()\n",
    "\n",
    "while len(product_names_set) < len(sku_ids):\n",
    "    product_names_set.add(generate_realistic_product_name())\n",
    "\n",
    "product_details = list(product_names_set)\n",
    "product_categories=[product_name[0] for product_name in product_details]\n",
    "product_names=[product_name[1] for product_name in product_details]\n",
    "\n",
    "product_cost_prices=[generate_price_for_category(product_category) for product_category in product_categories]\n",
    "product_selling_prices=[int(product_price*(1+random.randint(5,50)/100)) for product_price in product_cost_prices]\n",
    "\n",
    "\n",
    "sku_clusters = list(sku_cluster_explanations.values())\n",
    "inventory = pd.DataFrame({\n",
    "    \"sku_id\": sku_ids,\n",
    "    \n",
    "    \"product_name\": product_names,\n",
    "    \"product_category\": product_categories,\n",
    "    \"current_stock\": [random.randint(0, 200) for _ in sku_ids],\n",
    "    \"max_capacity\": [random.randint(0, 200) for _ in sku_ids],\n",
    "    #\"reorder_threshold\": [random.randint(20, 100) for _ in sku_ids],\n",
    "    \"lead_time_days\": [random.randint(1, 7) for _ in sku_ids],\n",
    "    \"supplier_id\": [random.choice(suppliers[\"supplier_id\"]) for _ in sku_ids],\n",
    "    \"cost_price\": product_cost_prices,\n",
    "    \"current_selling_price\": product_selling_prices,\n",
    "    \"cluster_id\":[random.randint(0, 5) for _ in sku_ids],\n",
    "    \"cluster_info\":[random.choice(sku_clusters) for _ in sku_ids],\n",
    "    \"store_id\": [\"STORE01\" for _ in sku_ids],\n",
    "    \"product_details\": [fake.sentence(nb_words=6) for _ in sku_ids]\n",
    "})\n",
    "#make sure max_stock is higher than current_stock\n",
    "inventory['max_capacity']=inventory[['current_stock','max_capacity']].max(axis=1)\n",
    "\n",
    "inventory['reorder_threshold'] = inventory.apply(lambda x:random.randint(int(x['max_capacity']*0.15),int(x['max_capacity']*0.30)),axis=1)\n",
    "\n",
    "##add categories \n",
    "sku_shuffled=random.shuffle(sku_ids)\n",
    "seasonal_skus = ranked_sales_data.index[0:10].tolist()\n",
    "new_arrival_skus = ranked_sales_data.index[10:20].tolist()\n",
    "stagnant_skus = ranked_sales_data.index[-10:].tolist()\n",
    "sku_category_map = {}\n",
    "sku_category_map.update({sku: 'Seasonal Items' for sku in seasonal_skus})\n",
    "sku_category_map.update({sku: 'New Arrivals' for sku in new_arrival_skus})\n",
    "sku_category_map.update({sku: 'Stagnant Items' for sku in stagnant_skus})\n",
    "inventory['category'] = inventory['sku_id'].map(sku_category_map).astype(str)\n",
    "inventory.to_csv(\"inventory.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba17cd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "campaigns = pd.DataFrame({\n",
    "    \"campaign_id\": [f\"CAMPAIGN{i+1:04}\" for i in range(150)],\n",
    "    \"sku_id\": [random.choice(sku_ids) for _ in range(150)],\n",
    "    \"start_date\": [fake.date_between(start_date='-6m', end_date='-1m') for _ in range(150)],\n",
    "    \"end_date\": [fake.date_between(start_date='-1m', end_date='today') for _ in range(150)],\n",
    "    \"discount_percent\": [random.choice([5, 10, 15, 20, 25, 30]) for _ in range(150)],\n",
    "    \"customer_group\": [random.choice(['Silver', 'Gold', 'Platinum', 'All']) for _ in range(150)],\n",
    "    \"success_rate\": [round(random.uniform(0.1, 0.95), 2) for _ in range(150)]\n",
    "})\n",
    "\n",
    "# Ensure end_date > start_date\n",
    "campaigns[\"end_date\"] = campaigns.apply(\n",
    "    lambda row: fake.date_between(start_date=row[\"start_date\"], end_date='today'), axis=1\n",
    ")\n",
    "\n",
    "campaigns.to_csv(\"campaigns.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97a65040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database 'data/retail_analytics.db' and tables created successfully.\n",
      "Loading data from CSV files...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import (\n",
    "    create_engine, Column, String, Integer, Float, Boolean, Date, ForeignKey\n",
    ")\n",
    "from sqlalchemy.orm import declarative_base, relationship\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Supplier(Base):\n",
    "    __tablename__ = 'suppliers'\n",
    "    supplier_id = Column(String, primary_key=True)\n",
    "    supplier_name = Column(String)\n",
    "    contact_email = Column(String)\n",
    "    phone_number = Column(String)\n",
    "    region = Column(String)\n",
    "\n",
    "    products = relationship(\"Product\", back_populates=\"supplier\")\n",
    "    reorders = relationship(\"Reorder\", back_populates=\"supplier\")\n",
    "    supplier_skus = relationship(\"SupplierSKU\", back_populates=\"supplier\")\n",
    "\n",
    "class Store(Base):\n",
    "    __tablename__ = 'stores'\n",
    "    store_id = Column(String, primary_key=True)\n",
    "    \n",
    "    inventory = relationship(\"Product\", back_populates=\"store\")\n",
    "    sales = relationship(\"Sale\", back_populates=\"store\")\n",
    "\n",
    "class Customer(Base):\n",
    "    __tablename__ = 'customers'\n",
    "    customer_id = Column(String, primary_key=True)\n",
    "    name = Column(String)\n",
    "    region = Column(String)\n",
    "    segment = Column(String)\n",
    "    cluster_id = Column(Integer)\n",
    "    cluster_info = Column(String)\n",
    "    gender = Column(String)\n",
    "    birthdate = Column(Date)\n",
    "    contact_info = Column(String)\n",
    "    buying_power = Column(Integer)\n",
    "    fav_category = Column(String)\n",
    "    last_purchase_date = Column(Date)\n",
    "    income_level = Column(String)\n",
    "    location = Column(String)\n",
    "    no_of_dependents = Column(Integer)\n",
    "    purchase_frequency = Column(Integer)\n",
    "    click_on_marketing_emails = Column(Boolean)\n",
    "    return_rate = Column(Float)\n",
    "    usage_frequency = Column(String)\n",
    "    total_spend = Column(Float)\n",
    "    loyalty = Column(String)\n",
    "\n",
    "    sales = relationship(\"Sale\", back_populates=\"customer\")\n",
    "\n",
    "class Product(Base):\n",
    "    __tablename__ = 'products'\n",
    "    sku_id = Column(String, primary_key=True)\n",
    "    product_name = Column(String)\n",
    "    product_category = Column(String)\n",
    "    current_stock = Column(Integer)\n",
    "    max_capacity = Column(Integer)\n",
    "    reorder_threshold = Column(Integer)\n",
    "    cost_price = Column(Float)\n",
    "    current_selling_price = Column(Float)\n",
    "    product_details = Column(String)\n",
    "    category = Column(String)\n",
    "    cluster_id = Column(Integer)\n",
    "    cluster_info = Column(String)\n",
    "    store_id = Column(String, ForeignKey('stores.store_id'))\n",
    "\n",
    "\n",
    "\n",
    "    supplier = relationship(\"Supplier\", back_populates=\"products\")\n",
    "    store = relationship(\"Store\", back_populates=\"inventory\")\n",
    "    sales = relationship(\"Sale\", back_populates=\"product\")\n",
    "    campaigns = relationship(\"Campaign\", back_populates=\"product\")\n",
    "    reorders = relationship(\"Reorder\", back_populates=\"product\")\n",
    "    supplier_skus = relationship(\"SupplierSKU\", back_populates=\"product\")\n",
    "\n",
    "class Sale(Base):\n",
    "    __tablename__ = 'sales'\n",
    "    sale_id = Column(String, primary_key=True)\n",
    "    quantity = Column(Integer)\n",
    "    sale_date = Column(Date)\n",
    "    status = Column(String)\n",
    "    fulfilled = Column(Boolean)\n",
    "    amount = Column(Float)\n",
    "    coupon = Column(String, nullable=True)\n",
    "\n",
    "    customer_id = Column(String, ForeignKey('customers.customer_id'))\n",
    "    sku_id = Column(String, ForeignKey('products.sku_id'))\n",
    "    store_id = Column(String, ForeignKey('stores.store_id'))\n",
    "\n",
    "    customer = relationship(\"Customer\", back_populates=\"sales\")\n",
    "    product = relationship(\"Product\", back_populates=\"sales\")\n",
    "    store = relationship(\"Store\", back_populates=\"sales\")\n",
    "\n",
    "class Campaign(Base):\n",
    "    __tablename__ = 'campaigns'\n",
    "    campaign_id = Column(String, primary_key=True)\n",
    "    start_date = Column(Date)\n",
    "    end_date = Column(Date)\n",
    "    discount_percent = Column(Integer)\n",
    "    customer_group = Column(String)\n",
    "    success_rate = Column(Float)\n",
    "\n",
    "    sku_id = Column(String,ForeignKey('products.sku_id'))\n",
    "    product = relationship(\"Product\", back_populates=\"campaigns\")\n",
    "\n",
    "\n",
    "class DemandForecast(Base):\n",
    "    __tablename__ = 'demand_forecast'\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    sku_id = Column(String)\n",
    "    quantity = Column(Float)\n",
    "\n",
    "    sku_id = Column(String,ForeignKey('products.sku_id'))\n",
    "    product = relationship(\"Product\", back_populates=\"campaigns\")\n",
    "\n",
    "class Reorder(Base):\n",
    "    __tablename__ = 'reorders'\n",
    "    reorder_id = Column(String, primary_key=True)\n",
    "    reorder_qty = Column(Integer)\n",
    "    reorder_date = Column(Date)\n",
    "    status = Column(String)\n",
    "    price_per_unit = Column(Float)\n",
    "    reorder_fulfilment_date = Column(Date, nullable=True)\n",
    "\n",
    "    sku_id = Column(String, ForeignKey('products.sku_id'))\n",
    "    supplier_id = Column(String, ForeignKey('suppliers.supplier_id'))\n",
    "\n",
    "    product = relationship(\"Product\", back_populates=\"reorders\")\n",
    "    supplier = relationship(\"Supplier\", back_populates=\"reorders\")\n",
    "\n",
    "class SupplierSKU(Base):\n",
    "    __tablename__ = 'supplier_skus'\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    min_purchase_qty = Column(Integer)\n",
    "    max_purchase_qty = Column(Integer)\n",
    "    min_price = Column(Float)\n",
    "    max_price = Column(Float)\n",
    "    lead_time_days = Column(Integer)\n",
    "\n",
    "    sku_id = Column(String, ForeignKey('products.sku_id'))\n",
    "    supplier_id = Column(String, ForeignKey('suppliers.supplier_id'))\n",
    "\n",
    "    product = relationship(\"Product\", back_populates=\"supplier_skus\")\n",
    "    supplier = relationship(\"Supplier\", back_populates=\"supplier_skus\")\n",
    "\n",
    "## we save our recommendations here\n",
    "class DraftPurchaseOrder(Base):\n",
    "    __tablename__ = 'draft_purchase_order'\n",
    "    id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "    sku_id = Column(String, ForeignKey('products.sku_id'))\n",
    "    supplier_id = Column(String, ForeignKey('suppliers.supplier_id'))\n",
    "    quantity_to_order = Column(Integer)\n",
    "    cost_per_unit = Column(Float)\n",
    "    lead_time = Column(Integer)\n",
    "\n",
    "    # Relationships\n",
    "    product = relationship(\"Product\", backref=\"draft_orders\")\n",
    "    supplier = relationship(\"Supplier\", backref=\"draft_orders\")\n",
    "\n",
    "\n",
    "# 3. Create Engine and Tables\n",
    "DB_NAME = \"data/retail_analytics.db\"\n",
    "engine = create_engine(f\"sqlite:///{DB_NAME}\")\n",
    "Base.metadata.create_all(engine)\n",
    "print(f\"Database '{DB_NAME}' and tables created successfully.\")\n",
    "\n",
    "# 4. Load Data using Pandas\n",
    "\n",
    "# --- File Paths ---\n",
    "# Assume CSV files are in the same directory as the script.\n",
    "inventory_file = 'inventory.csv'\n",
    "campaigns_file = 'campaigns.csv'\n",
    "reorders_file = 'reorders.csv'\n",
    "sales_file = 'sales_data.csv'\n",
    "supplier_sku_file = 'supplier-sku.csv'\n",
    "supplier_file = 'supplier.csv'\n",
    "customer_file = 'customer.csv'\n",
    "forecast_file = 'demand_forecast.csv'\n",
    "\n",
    "print(\"Loading data from CSV files...\")\n",
    "inventory_df = pd.read_csv(inventory_file).drop(['lead_time_days','supplier_id'],axis=1)\n",
    "\n",
    "campaigns_df = pd.read_csv(campaigns_file, parse_dates=['start_date', 'end_date'])\n",
    "\n",
    "reorders_df = pd.read_csv(reorders_file, parse_dates=['reorder_date', 'reorder_fulfilment_date'])\n",
    "\n",
    "sales_df = pd.read_csv(sales_file, parse_dates=['sale_date'])\n",
    "\n",
    "supplier_sku_df = pd.read_csv(supplier_sku_file)\n",
    "\n",
    "supplier_df = pd.read_csv(supplier_file)\n",
    "\n",
    "forecast_df = pd.read_csv(forecast_file)\n",
    "\n",
    "customer_df = pd.read_csv(customer_file, parse_dates=['birthdate', 'last purchase date'])\n",
    "customer_df['birthdate']=customer_df['birthdate'].dt.date\n",
    "customer_df['last purchase date']=customer_df['last purchase date'].dt.date\n",
    "#rename this one, not sure why this was the initial name\n",
    "customer_df = customer_df.rename(columns={'usage frequency of (app or site)': 'usage_frequency'})\n",
    "#replace all spaces with underscores\n",
    "customer_df.columns=[col.replace(' ','_',5) for col in customer_df.columns.tolist()]\n",
    "\n",
    "store_ids = inventory_df['store_id'].unique()\n",
    "stores_df = pd.DataFrame(store_ids, columns=['store_id'])\n",
    "stores_df.to_sql('stores', con=engine, if_exists='replace', index=False)\n",
    "supplier_df.to_sql('suppliers', con=engine, if_exists='replace', index=False)\n",
    "customer_df.to_sql('customers', con=engine, if_exists='replace', index=False)\n",
    "inventory_df.to_sql('products', con=engine, if_exists='replace', index=False)\n",
    "sales_df.to_sql('sales', con=engine, if_exists='replace', index=False)\n",
    "campaigns_df.to_sql('campaigns', con=engine, if_exists='replace', index=False)\n",
    "reorders_df.to_sql('reorders', con=engine, if_exists='replace', index=False)\n",
    "supplier_sku_df.to_sql('supplier_skus', con=engine, if_exists='replace', index=False)\n",
    "forecast_df.to_sql('demand_forecast', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba73da38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create/replace demand_forecast\n",
    "#create out_of_stock \n",
    "import pandas as pd\n",
    "forecast_df=pd.read_csv(\"data/demand_forecast.csv\")\n",
    "forecast_df['days_predicted_for']=7\n",
    "oos=pd.read_csv(\"data/out_of_stock.csv\")\n",
    "oos['days_predicted_for']=7\n",
    "# oos.to_sql('out_of_stock', con=engine, if_exists='replace', index=False)\n",
    "# forecast_df.to_sql('demand_forecast', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c15d7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "637"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oos.to_sql('out_of_stock', con=engine, if_exists='replace', index=False)\n",
    "forecast_df.to_sql('demand_forecast', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca25e499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "from sqlalchemy import inspect, text, create_engine\n",
    "\n",
    "def get_formatted_sample_rows(engine, table_name: str, num_rows: int) -> str:\n",
    "    \"\"\"\n",
    "    Fetches and formats sample rows from a table in the style of LangChain.\n",
    "    \"\"\"\n",
    "    with engine.connect() as connection:\n",
    "        query = text(f'SELECT * FROM \"{table_name}\" ORDER BY RANDOM() LIMIT {num_rows}')\n",
    "        sample_rows_result = connection.execute(query)\n",
    "        columns = sample_rows_result.keys()\n",
    "        sample_rows = sample_rows_result.fetchall()\n",
    "\n",
    "    formatted_rows = [\n",
    "        f\"/*\",\n",
    "        f\"{len(sample_rows)} rows from {table_name} table:\",\n",
    "        \"\\t\".join(columns),\n",
    "    ]\n",
    "    for row in sample_rows:\n",
    "        formatted_rows.append(\"\\t\".join(str(value) for value in row))\n",
    "    formatted_rows.append(\"*/\")\n",
    "    return \"\\n\".join(formatted_rows)\n",
    "\n",
    "def generate_custom_table_info(db_uri: str, table_names:list= [], distinct_value_threshold: int = 40, sample_rows_to_include: int=5):\n",
    "    \"\"\"\n",
    "    Connects to a database, inspects its schema, and generates a\n",
    "    custom table info dictionary for LangChain's SQLDatabase.\n",
    "\n",
    "    For columns with a number of distinct values below the threshold,\n",
    "    it fetches and includes those values in the table's CREATE statement\n",
    "    as a comment.\n",
    "    \"\"\"\n",
    "    engine = create_engine(db_uri)\n",
    "    inspector = inspect(engine)\n",
    "    custom_table_info = {}\n",
    "    \n",
    "    if not table_names:\n",
    "      table_names = inspector.get_table_names()\n",
    "\n",
    "    with engine.connect() as connection:\n",
    "        for table_name in table_names:\n",
    "            print(f\"Processing table: {table_name}\")\n",
    "            create_statement_parts = [f\"CREATE TABLE {table_name} (\"]\n",
    "            \n",
    "            columns = inspector.get_columns(table_name)\n",
    "            column_defs = []\n",
    "\n",
    "            for column in columns:\n",
    "                col_name = column['name']\n",
    "                col_type = column['type']\n",
    "                col_def = f\"\\t {col_name} {col_type}\"\n",
    "                \n",
    "                try:\n",
    "                    # Query for the count of distinct values\n",
    "                    count_query = text(f'SELECT COUNT(DISTINCT \"{col_name}\") FROM \"{table_name}\"')\n",
    "                    distinct_count = connection.execute(count_query).scalar_one_or_none()\n",
    "\n",
    "                    if distinct_count is not None and distinct_count < distinct_value_threshold:\n",
    "                        values_query = text(f'SELECT DISTINCT \"{col_name}\" FROM \"{table_name}\" WHERE \"{col_name}\" IS NOT NULL')\n",
    "                        distinct_values = [str(row[0]) for row in connection.execute(values_query)]\n",
    "                        \n",
    "                        values_str = \", \".join(distinct_values)\n",
    "                        col_def += f\"Distinct values: {values_str}\"\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not process column '{col_name}' in table '{table_name}'. Error: {e}\")\n",
    "\n",
    "                column_defs.append(col_def)\n",
    "\n",
    "            create_statement_parts.append(\",\\n\".join(column_defs))\n",
    "            create_statement_parts.append(\")\")\n",
    "            create_statement= \"\\n\".join(create_statement_parts)\n",
    "\n",
    "            sample_rows_str = \"\"\n",
    "            if sample_rows_to_include > 0:\n",
    "                print(f\"  -> Fetching {sample_rows_to_include} sample rows...\")\n",
    "                sample_rows_str = get_formatted_sample_rows(engine, table_name, sample_rows_to_include)\n",
    "\n",
    "            custom_table_info[table_name] = f\"{create_statement}\\n{sample_rows_str}\"\n",
    "\n",
    "    return custom_table_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f0a3503",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this wipes data from `new customers` \n",
    "import sqlite3\n",
    "DB_FILE = 'data/retail_analytics.db'\n",
    "conn = sqlite3.connect(DB_FILE)\n",
    "conn.execute(\"\"\"UPDATE customers SET cluster_info = 'unavailable' WHERE customer_id IN (SELECT customer_id FROM (SELECT T1.customer_id FROM customers AS T1 INNER JOIN sales AS T2 ON T1.customer_id = T2.customer_id ORDER BY T2.sale_date DESC LIMIT 10))\"\"\"); \n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51e573af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing table: products\n",
      "  -> Fetching 5 sample rows...\n",
      "Processing table: draft_purchase_order\n",
      "  -> Fetching 5 sample rows...\n",
      "Processing table: sales\n",
      "  -> Fetching 5 sample rows...\n",
      "Processing table: reorders\n",
      "  -> Fetching 5 sample rows...\n",
      "Processing table: customers\n",
      "  -> Fetching 5 sample rows...\n",
      "Processing table: supplier_skus\n",
      "  -> Fetching 5 sample rows...\n",
      "Processing table: suppliers\n",
      "  -> Fetching 5 sample rows...\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "tables = ['products','draft_purchase_order','sales','reorders','customers','supplier_skus','suppliers']\n",
    "DB_FILE = 'data/retail_analytics.db'\n",
    "DB_URI = f\"sqlite:///{DB_FILE}\"\n",
    "DISTINCT_VALUE_THRESHOLD = 40 \n",
    "\n",
    "included_columns=[]\n",
    "custom_info = generate_custom_table_info(\n",
    "    table_names=tables,\n",
    "    db_uri=DB_URI,\n",
    "    distinct_value_threshold=DISTINCT_VALUE_THRESHOLD,sample_rows_to_include=5\n",
    "    \n",
    ")\n",
    "\n",
    "db = SQLDatabase.from_uri(DB_URI, custom_table_info= custom_info)\n",
    "db.get_table_info(tables)\n",
    "with open('data/db_table_info.json','w') as fp:\n",
    "    json.dump(custom_info,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6e830b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1615dfdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9cf26d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08bd105",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
